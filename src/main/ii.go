package main

import "os"
import "fmt"
import "mapreduce"
import "strings"
import "sort"
import "unicode"
import "strconv"

// The mapping function is called once for each piece of the input.
// In this framework, the key is the name of the file that is being processed,
// and the value is the file's contents. The return value should be a slice of
// key/value pairs, each represented by a mapreduce.KeyValue.


//wc.go
//func mapF(filename string, contents string) []mapreduce.KeyValue {
//	// Your code here (Part II).
//	// 把contents拆分成单词，并组成pairs
//	var words []string
//	var kvMap map[string]int 
//	kvMap = make(map[string]int)
//	var ret []mapreduce.KeyValue
//	//分割函数
//	splitFun := func(c rune) bool{
//		return !unicode.IsLetter(c) && !unicode.IsNumber(c)
//	}
//	words = strings.FieldsFunc(contents,splitFun)
//	//分割了之后在value中统计Key(word)出现的频率
//	for _,w := range words{
//		kvMap[w]++;
//	}
//	for k , _:= range kvMap{
//		ret = append(ret,mapreduce.KeyValue{k,strconv.Itoa(kvMap[k])})
//	}
//	//fmt.Println(filename,"mapF end\n")
//	return ret
//
//}
//
////
//// The reduce function is called once for each key generated by the
//// map tasks, with a list of all the values created for that key by
//// any map task.
////
//func reduceF(key string, values []string) string {
//	// Your code here (Part II).
//	//fmt.Println("reduceF start\n")
//	//fmt.Println("string values:",len(values))
//	//计算所有values的整形和
//	count := 0
//	//print("key :",key,"  values: ",values,"\n")
//	for _,v := range values{
//		tmp, err := strconv.Atoi(v)
//		//print("value:",v,"\n")
//		if err!=nil{
//			log.Fatal("wc.go reduceF() : ",err)
//		}
//		count += tmp
//	}
//	return strconv.Itoa(count)
//}


//key->value 为word->file
func mapF(document string, value string) (res []mapreduce.KeyValue) {

	// words := strings.FieldsFunc(value, func(r rune) bool {
	// 	return !unicode.IsLetter(r)
	// })
	// s := make(map[string]bool)
	// for _, word := range words {
	// 	lower := strings.ToLower(word)
	// 	upper := strings.ToUpper(word)
	// 	_, hasUpper := s[lower]
	// 	_, hasLower := s[upper]
	// 	if !hasLower && !hasUpper {
	// 		if lower == word {
	// 			s[lower] = true
	// 		} else if upper == word {
	// 			s[upper] = true
	// 		}
	// 	}
	// }

	//for k, _ := range s {
	//	res = append(res, mapreduce.KeyValue{k, document})
	//}
	//return

	// Your code here (Part V).
	var words []string
	hasExist := make(map[string]bool)

	splitFunc := func(c rune) bool{
			return !unicode.IsLetter(c) && !unicode.IsNumber(c)
	}
	words = strings.FieldsFunc(value,splitFunc)
	for _,w := range words{
		//upper:= strings.ToUpper(w)
		//lower:= strings.ToLower(w)
		//_,hasLower = hasExist[upper]
		if !hasExist[w]{
			hasExist[w]=true
			res = append(res,mapreduce.KeyValue{w,document})
		} 
	}
	return
}

// The reduce function is called once for each key generated by Map, with a
// list of that key's string value (merged across all inputs). The return value
// should be a single output value for that key.
func reduceF(key string, values []string) string {
	// Your code here (Part V).
	sort.Strings(values)
	ret:=""
	prio:=""
	ret+= (strconv.Itoa(len(values))+" ")
	for idx,item := range values{
		if item==prio{
			continue
		}
		if idx!=0 {
			ret+=","
		}
		prio=item	
		ret+=item
	}
	return ret
	//直接下面一句就可以
	//return strconv.Itoa(len(values)) + " " + strings.Join(values, ",")


}

// Can be run in 3 ways:
// 1) Sequential (e.g., go run wc.go master sequential x1.txt .. xN.txt)
// 2) Master (e.g., go run wc.go master localhost:7777 x1.txt .. xN.txt)
// 3) Worker (e.g., go run wc.go worker localhost:7777 localhost:7778 &)
func main() {
	if len(os.Args) < 4 {
		fmt.Printf("%s: see usage comments in file\n", os.Args[0])
	} else if os.Args[1] == "master" {
		var mr *mapreduce.Master
		if os.Args[2] == "sequential" {
			mr = mapreduce.Sequential("iiseq", os.Args[3:], 3, mapF, reduceF)
		} else {
			mr = mapreduce.Distributed("iiseq", os.Args[3:], 3, os.Args[2])
		}
		mr.Wait()
	} else {
		mapreduce.RunWorker(os.Args[2], os.Args[3], mapF, reduceF, 100, nil)
	}
}
